# DUSt3R_PQK 工作流指导（v1）

> 目标：把**配置→运行→记录→评测→出图→归档**串成一条可重复、可扩展的流水线。本文不是讲“放哪儿”，而是规定**怎么工作**与**何时改哪些文件**。

---

## 0. 角色与工件（Artifacts）

* **人**：你（实验 Owner），脚本维护者（可同一人）。
* **核心工件**：

  1. `configs/workload.yaml` —— **工作负载口径**：输入形状、配对规则、数据清单与校准集规则（谁跑实验都遵守）。
  2. `configs/eval.yaml` —— **评测口径**：要算哪些质量/效率/资源指标、成功/止损阈值、早停、报告导出位置。
  3. `logs/unified_log_schema.json` —— **统一日志字段**：所有实验写出同一套字段，保证可比/可复现。
* **配套工件**（在后续阶段会用到）：

  * `configs/distill.yaml` / `quant.yaml` / `prune.yaml`：对应 K/Q/P 的超参与开关。
  * `schedule/TaskCards/*.md`：每个实验一张**任务卡**（目标/步骤/阈值/止损/GPU 预算）。
  * `scripts/*.py`：`run_distill.py / run_quant.py / run_prune.py / run_eval.py / export_onnx_trt.py` 等。
  * `reports/*`：汇总表、图表（tradeoff、ablation、latency）。

> **工作原则**：口径先定→任何脚本都读同一口径→产出统一日志→统一汇总与出图。

---

## 1. 生命周期总览（从新实验到归档）

```
[准备口径] → [挑任务卡] → [填配置] → [运行脚本] → [写统一日志] → [自动评测/出表] → [边侧测评(可选)] → [里程碑复盘/归档]
```

* **准备口径**：只有在需要改变“输入/评测规则”时才改 `workload.yaml` / `eval.yaml`；默认稳定不动。
* **挑任务卡**：从 `schedule/TaskCards` 选或新建一张（例如 A1 K-only）。
* **填配置**：只改本实验的 `distill.yaml / quant.yaml / prune.yaml`（不要动口径文件）。
* **运行脚本**：所有脚本第一步读取 `workload.yaml` 与 `eval.yaml`，第二步读取对应实验配置。
* **写统一日志**：脚本结束写一条（或多条）JSON，字段必须符合 `unified_log_schema.json`。
* **自动评测/出表**：`run_eval.py` 或收尾函数根据 `eval.yaml` 指标生成 `reports/result_table.xlsx / summary.csv`。
* **边侧测评**：如需 Jetson，按 `workload.yaml: edge_profile` 导出 TensorRT、实测时延与功耗。
* **里程碑复盘**：每周一次，把通过/失败/止损的实验与花费 GPU 小时记录到 `schedule/DUSt3R-PQK_实验任务表.md`。

---

## 2. 三个文件在工作流中的作用与修改时机

### 2.1 `configs/workload.yaml`（**工作负载口径**）

* **你要做什么**：

  * 只在**确定/变更**：输入尺寸（如 512→640）、pair 图生成策略、评测清单路径、量化校准集规则时修改。
  * 修改后，**所有实验自动沿用**，无需逐个脚本改参数。
* **你不要做什么**：

  * 不要在每个实验里随意改 input shape；如需做“输入尺度消融”，新建**任务卡**并明确口径变更与对比目的。
* **质控动作**：改完后跑一次“干跑校验”（见 §4）。

### 2.2 `configs/eval.yaml`（**评测与阈值口径**）

* **你要做什么**：

  * 统一定义：质量/效率/资源指标；成功阈与止损线；早停上限；报告导出路径。
  * 只在审稿反馈或方向变化（例如新增 `power_W`）时更新。
* **你不要做什么**：

  * 不要为某个实验单独放宽阈值（例如把质量跌幅改大）。个别例外请在**任务卡**注明，而不是改口径文件。
* **质控动作**：改完后跑“干跑校验”。

### 2.3 `logs/unified_log_schema.json`（**统一日志字段**）

* **你要做什么**：

  * 所有脚本写日志时**严格按字段名**输出必填列（`required`）。
  * 新增字段（例如 `calibration_set_hash`、`edge_device.power_peak_W`）时，先升级 schema 版本，再改脚本。
* **你不要做什么**：

  * 不要随意更名/删字段，避免旧实验数据无法合并。
* **质控动作**：每次脚本输出后，用 `jsonschema` 校验（可在 `run_*` 里内置）。

---

## 3. 日常操作 SOP（上手即用）

### 3.1 新建一次实验（示例：K→Q 主线）

1. 从 `schedule/TaskCards/` 复制模板，新建 `KQ_D1.md`，填：目标、阈值、止损、GPU 小时预算。
2. 打开 `configs/distill.yaml`（或 `quant.yaml`）：填 teacher 路径、student 缩减比例、损失权重/温度、QAT 位宽、keep-list 等。
3. 运行：

   ```bash
   python scripts/run_distill.py --workload configs/workload.yaml --eval configs/eval.yaml --cfg configs/distill.yaml --log logs/D1_distill.json
   ```
4. 脚本末尾自动 `run_eval.py`，并写：`logs/D1_eval.json`、更新 `reports/result_table.xlsx`。
5. 若达不到 `eval.yaml` 阈值，触发早停/止损，回到任务卡改动（例如减剪枝率/调整 β/T）。

### 3.2 量化（Q-only/接蒸馏后）

```bash
python scripts/run_quant.py \
  --workload configs/workload.yaml \
  --eval configs/eval.yaml \
  --cfg configs/quant.yaml \
  --ckpt outputs/checkpoints/student_best.pth \
  --log logs/B1_quant.json
```

* PTQ→QAT 切换由 `eval.yaml: thresholds.quality_drop_q_only_pct` 控制。

### 3.3 剪枝（P-only 或接入 K）

```bash
python scripts/run_prune.py \
  --workload configs/workload.yaml \
  --eval configs/eval.yaml \
  --cfg configs/prune.yaml \
  --ckpt outputs/checkpoints/teacher_or_student.pth \
  --log logs/C1_prune.json
```

---

## 4. 干跑校验（不加载模型、不需要数据）

> 目的：改了口径文件后，快速验证**语法/字段/范围**正确，脚本对接无痛。

步骤（建议写成 `scripts/devcheck.py`）：

1. 读 `workload.yaml`、`eval.yaml`；断言 `input.shape=[1,3,H,W]` 且 H=W∈{384,512,640}；`pair_graph.k≥1`；阈值在合理区间。
2. 生成一条**虚拟**结果 JSON，字段与 `unified_log_schema.json` 完全匹配，用 `jsonschema` 校验。
3. 打印 `PASS`；否则报出**具体字段**与**取值错误**。

---

## 5. 版本控制与变更策略

* **版本号**：`workload.yaml (v1.0→v1.1)`、`eval.yaml (v1.0→v1.1)`；在文件首行加注释版本与变更点。
* **变更管理**：

  * 仅当需要改变输入/评测**规则**时才升版（例如输入 512→640、新增指标 `power_W`）。
  * 升版后，老实验**不回填**；新实验起按新口径写。

---

## 6. 失败与止损机制（统一）

* 连续 `no_improve_ckpt` 次无提升 → 早停。
* 单实验 GPU 小时超过任务卡上限的 **120%** → 止损，回到任务卡调整方案。
* 量化单独节点允许精度跌幅 **≤2%**；主线（K 或 K→Q）控制在 **≤1.5%**。

---

## 7. 汇总与出图（自动化）

* 所有日志（`logs/*.json`）由 `scripts/aggregate.py` 合并，输出：

  * `reports/result_table.xlsx`
  * `reports/summary.csv` / `summary.json`
  * `reports/plots/*`（tradeoff、ablation、latency-p50/p95）
* 图表与表格字段名**完全来自 schema**，无需每次手改列名。

---

## 8. 端侧（Jetson）评测流程（可选）

1. `export_onnx_trt.py` 读取 `workload.yaml.input.shape`，导出 ONNX 与 TensorRT engine。
2. 在 Jetson 上运行 `edge_eval.py`：记录 `t_pair_p50/p95`、`pairs/sec`、`power_avg/peak`、`throttle`，按 schema 写入日志。
3. 汇总时自动把 Edge 与 GPU 侧放到一张表/一张图中（不同列）。

---

## 9. 你每天应该怎么做（Checklist）

* [ ] 当天是否需要修改口径？（绝大多数情况 **不需要**）
* [ ] 选择/新建任务卡，确认目标、阈值、止损、GPU 预算。
* [ ] 只改对应 `distill.yaml / quant.yaml / prune.yaml`；不动口径文件。
* [ ] 运行；看日志是否符合 `unified_log_schema.json`；失败按止损回退。
* [ ] 更新 `reports/*`、记录 `schedule/实验任务表` 的进展与耗时。

---

## 10. 常见误区

* **在单个实验里私改输入或指标** → 结果不可比；应通过升版口径或任务卡注明“变更口径的消融”。
* **日志字段随意增删** → 无法合并；应先升级 schema 再改脚本。
* **阈值随实验漂移** → 审稿人无法把握贡献；阈值在 `eval.yaml` 固化。

---

## 11. 最小落地行动（今天就能做）

1. 不改口径，创建 1 张任务卡（K-only A1）。
2. 填 `configs/distill.yaml` 的基础 profile（teacher 路径、学生缩减 30%、T/β/γ 初值）。
3. 写 `scripts/devcheck.py`（10–20 行）做干跑校验。
4. 开跑第一条蒸馏小实验（devcheck 通过后）。

---

> 这就是以后你的“工作方式”：**口径稳定、任务卡驱动、统一日志、自动出表**。当你在任务卡动手时，不用再想“哪些指标/怎样算/如何导出”，因为这些都已由 `workload.yaml / eval.yaml / unified_log_schema.json` 固化。ChatGPT 说：

结论：它们三份文件已经把“统一口径+统一评测+统一日志”的工作流骨架钉住了，但还不等于“能自动跑起来的完整流水线”。要从“骨架”变成“可跑”，还缺3类东西：

这三份文件=已完成的“骨架”

workload.yaml：统一输入/配对/数据清单/校准集口径（所有实验共享的入口）。

eval.yaml：统一评测指标/阈值/早停/报告导出口径（所有结果可比）。

unified_log_schema.json：统一日志字段（所有实验能汇总、出表、画图）。

还需补齐=把骨架变成“可跑”的最小件

实验专用配置（每类实验一份）

configs/distill.yaml（K）

configs/quant.yaml（Q）

configs/prune.yaml（P）

执行脚本

scripts/run_distill.py、run_quant.py、run_prune.py、run_eval.py

（脚本第一步读取 workload.yaml/eval.yaml，第二步读取各自专用配置）

任务驱动

schedule/TaskCards/*.md（目标/阈值/止损/GPU预算/预计时长）

scripts/devcheck.py（干跑校验：读YAML+校验schema，不加载模型）

有了上面3类最小件，你就具备“选任务卡→改专用配置→一键运行→写统一日志→自动汇总出表”的完整工作流。
